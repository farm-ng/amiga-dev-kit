"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9653],{7359:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>d,frontMatter:()=>a,metadata:()=>i,toc:()=>m});var o=n(7462),r=(n(7294),n(3905));n(1839);const a={id:"transforms-and-poses",title:"Transforms & Poses"},s=void 0,i={unversionedId:"concepts/transforms_and_poses/transforms-and-poses",id:"concepts/transforms_and_poses/transforms-and-poses",title:"Transforms & Poses",description:"Fundamental Concepts",source:"@site/docs/concepts/transforms_and_poses/README.md",sourceDirName:"concepts/transforms_and_poses",slug:"/concepts/transforms_and_poses/",permalink:"/docs/concepts/transforms_and_poses/",draft:!1,editUrl:"https://github.com/farm-ng/amiga-dev-kit/tree/main/website/docs/concepts/transforms_and_poses/README.md",tags:[],version:"current",frontMatter:{id:"transforms-and-poses",title:"Transforms & Poses"},sidebar:"Concepts",previous:{title:"Concepts Index",permalink:"/docs/concepts/"},next:{title:"Tracks & Waypoints",permalink:"/docs/concepts/controller_101/"}},p={},m=[{value:"Fundamental Concepts",id:"fundamental-concepts",level:2},{value:"Frames of Reference",id:"frames-of-reference",level:3},{value:"Transformations",id:"transformations",level:3},{value:"Quaternions",id:"quaternions",level:4},{value:"Transform math",id:"transform-math",level:4},{value:"Poses",id:"poses",level:3},{value:"The farm-ng <code>Pose</code> proto",id:"the-farm-ng-pose-proto",level:3},{value:"Properties of Isometry3F64",id:"properties-of-isometry3f64",level:4},{value:"Resources",id:"resources",level:3}],l={toc:m};function d(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"fundamental-concepts"},"Fundamental Concepts"),(0,r.kt)("p",null,"Before we can create autonomy applications for our robot,\nwe need to understand where our robot and other points of reference are.\nThe following concepts are critical to understand if you wish\nto develop autonomous robotics applications with your Amiga."),(0,r.kt)("h3",{id:"frames-of-reference"},"Frames of Reference"),(0,r.kt)("p",null,"In robotics, a ",(0,r.kt)("strong",{parentName:"p"},"frame of reference"),'\n(often called a "',(0,r.kt)("strong",{parentName:"p"},"frame"),'", ',(0,r.kt)("strong",{parentName:"p"},"coordinate frame"),', or "',(0,r.kt)("strong",{parentName:"p"},"reference frame"),'")\nis a description of a coordinate system of 3 orthogonal axes (',(0,r.kt)("strong",{parentName:"p"},"x"),", ",(0,r.kt)("strong",{parentName:"p"},"y"),", & ",(0,r.kt)("strong",{parentName:"p"},"z"),") defined by\nthe position and orientation of the object."),(0,r.kt)("p",null,"The two primary frames you need to be aware of are:"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"World Frame (",(0,r.kt)("inlineCode",{parentName:"strong"},"world"),")"),":\nConventionally, this is a fixed frame representing the environment in which the robot operates.\nThink of it as an anchor point that doesn't move.\nIf using RTK GPS, a typical world frame coordinate system is defined at the location\nof your RTK base station."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Robot Frame (",(0,r.kt)("inlineCode",{parentName:"strong"},"robot"),")"),": This frame is attached to the robot.\nAs the robot moves, this frame moves with it.\nConsidering the robot is not a single point, it is important to define where on the robot\nis considered the center of the ",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," frame axes.\nAt farm-ng we choose the center of the robot (in length & width) at ground level."),(0,r.kt)("p",null,"Additional relevant frames for your Amiga-based robotics applications\nmay include the ",(0,r.kt)("inlineCode",{parentName:"p"},"camera")," frame, the ",(0,r.kt)("inlineCode",{parentName:"p"},"imu")," frame, the ",(0,r.kt)("inlineCode",{parentName:"p"},"gps_antenna")," frame, and so on."),(0,r.kt)("p",null,"Each ",(0,r.kt)("strong",{parentName:"p"},"reference frame")," is represented below as a set of red-green-blue axes.\nThe frames are connected by 6 degree-of-freedom ",(0,r.kt)("strong",{parentName:"p"},"transforms"),",\nrepresented below by yellow arrows."),(0,r.kt)("p",null,(0,r.kt)("img",{parentName:"p",src:"https://github.com/farm-ng/amiga-dev-kit/assets/53625197/656fff08-0296-4d81-8990-dc65d7f1af16",alt:"image"})),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"Image Credit: ",(0,r.kt)("a",{parentName:"em",href:"https://foxglove.dev/blog/understanding-ros-transforms"},"https://foxglove.dev/blog/understanding-ros-transforms"))),(0,r.kt)("h3",{id:"transformations"},"Transformations"),(0,r.kt)("p",null,"A ",(0,r.kt)("strong",{parentName:"p"},"transformation"),", or ",(0,r.kt)("strong",{parentName:"p"},"transform"),", describes how to move from one reference frame to another."),(0,r.kt)("p",null,"Typically in robotics we represent these transforms as an ",(0,r.kt)("strong",{parentName:"p"},"isometry")," transformation in 3D space.\nThis is a distance-preserving 6 degree-of-freedom (DOF) transformation\nthat includes a translation (3 DOF) and a rotation (the other 3 DOF)."),(0,r.kt)("p",null,"For instance, we can represent the transformation from the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," reference frame\nto the ",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," reference frame.\nOur naming convention at farm-ng is to call this the ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("inlineCode",{parentName:"strong"},"world_from_robot"))," transformation,\nfollowing a ",(0,r.kt)("inlineCode",{parentName:"p"},"<parent>_from_<child>")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"<frame_a>_from_<frame_b>")," naming convention."),(0,r.kt)("p",null,"This transform contains the ",(0,r.kt)("strong",{parentName:"p"},"translation")," along the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," ",(0,r.kt)("strong",{parentName:"p"},"x, y, z")," axes,\nas well as the ",(0,r.kt)("strong",{parentName:"p"},"rotation")," required to align the axes."),(0,r.kt)("p",null,"The ",(0,r.kt)("strong",{parentName:"p"},"translation"),", a 3-dimensional linear offset,\nis represented as a vector of ",(0,r.kt)("inlineCode",{parentName:"p"},"[x, y, z]")," coordinates in the parent reference frame."),(0,r.kt)("p",null,"The ",(0,r.kt)("strong",{parentName:"p"},"rotation"),", a 3-dimensional rotation, can be represented in a number of ways,\nbut typically is represented as a ",(0,r.kt)("strong",{parentName:"p"},"quaternion"),"."),(0,r.kt)("h4",{id:"quaternions"},"Quaternions"),(0,r.kt)("p",null,"Quaternions are a type of mathematical object used to represent rotations in 3D space."),(0,r.kt)("p",null,"Quaternions consist of four numbers ",(0,r.kt)("inlineCode",{parentName:"p"},"(x, y, z, w)")," (or sometimes in order ",(0,r.kt)("inlineCode",{parentName:"p"},"(w, x, y, z)"),").\n",(0,r.kt)("inlineCode",{parentName:"p"},"w")," represents the scalar (or real) part of the rotation\nand ",(0,r.kt)("inlineCode",{parentName:"p"},"x"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"y"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"z")," are the vector (or imaginary) parts."),(0,r.kt)("p",null,"Quaternions are an alternative to other methods like Euler angles or rotation matrices.\nQuaternions are particularly useful because they are compact,\navoid certain problems like gimbal lock, and can be more computationally efficient."),(0,r.kt)("h4",{id:"transform-math"},"Transform math"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Transforms")," can be mathematically manipulated to understand where ",(0,r.kt)("strong",{parentName:"p"},"coordinate frames"),"\nare in relation to one another.\nMost commonly, you will ",(0,r.kt)("strong",{parentName:"p"},"invert")," transforms and you will ",(0,r.kt)("strong",{parentName:"p"},"multiply")," transforms."),(0,r.kt)("p",null,"If you know the transform from the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," coordinate frame to the ",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," coordinate frame (",(0,r.kt)("inlineCode",{parentName:"p"},"world_from_robot"),"),\nyou can ",(0,r.kt)("strong",{parentName:"p"},"invert")," that transform to get the transform from the ",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," coordinate frame\nto the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," coordinate frame (",(0,r.kt)("inlineCode",{parentName:"p"},"robot_from_world"),")."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"world_from_robot = robot_from_imu^-1\n")),(0,r.kt)("p",null,"If you know two transforms with a common frame, you can ",(0,r.kt)("strong",{parentName:"p"},"multiply")," them."),(0,r.kt)("p",null,"Say you know ",(0,r.kt)("inlineCode",{parentName:"p"},"world_from_robot")," and the ",(0,r.kt)("inlineCode",{parentName:"p"},"robot_from_imu")," transform from your\n",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," frame to your ",(0,r.kt)("inlineCode",{parentName:"p"},"imu")," frame (where the IMU is on your robot).\nYou can calculate the transform from the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," frame to the ",(0,r.kt)("inlineCode",{parentName:"p"},"imu")," frame (",(0,r.kt)("inlineCode",{parentName:"p"},"world_from_imu"),")\nwith transform ",(0,r.kt)("strong",{parentName:"p"},"multiplication"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"world_from_imu = world_from_robot * robot_from_imu\n")),(0,r.kt)("h3",{id:"poses"},"Poses"),(0,r.kt)("p",null,"We tend to think of where our robot is as a ",(0,r.kt)("strong",{parentName:"p"},"pose"),", a combination of ",(0,r.kt)("strong",{parentName:"p"},"position")," and ",(0,r.kt)("strong",{parentName:"p"},"orientation"),".\nThe ",(0,r.kt)("strong",{parentName:"p"},"position")," being where the robot is, and the ",(0,r.kt)("strong",{parentName:"p"},"orientation")," being which way the robot is facing."),(0,r.kt)("p",null,"A pose is, however, undetermined as there needs to be a ",(0,r.kt)("strong",{parentName:"p"},"frame of reference")," the position\nand orientation are in.\nQueue ",(0,r.kt)("strong",{parentName:"p"},"transforms"),"!"),(0,r.kt)("p",null,"We can define the ",(0,r.kt)("strong",{parentName:"p"},"pose")," of our robot as the 6-DOF transformation from the ",(0,r.kt)("inlineCode",{parentName:"p"},"world")," frame\nto our ",(0,r.kt)("inlineCode",{parentName:"p"},"robot")," frame (",(0,r.kt)("inlineCode",{parentName:"p"},"world_from_robot"),")."),(0,r.kt)("p",null,"We are not limited to representing the ",(0,r.kt)("inlineCode",{parentName:"p"},"world_from_robot")," transformation as a pose.\nAny transform can be represented as a pose by correctly specifying the ",(0,r.kt)("inlineCode",{parentName:"p"},"frame_a")," (parent frame)\nand ",(0,r.kt)("inlineCode",{parentName:"p"},"frame_b")," (child frame) in our\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/farm-ng/farm-ng-core/blob/main/protos/farm_ng/core/pose.proto"},(0,r.kt)("strong",{parentName:"a"},(0,r.kt)("inlineCode",{parentName:"strong"},"Pose")," protobuf definition")),"."),(0,r.kt)("h3",{id:"the-farm-ng-pose-proto"},"The farm-ng ",(0,r.kt)("inlineCode",{parentName:"h3"},"Pose")," proto"),(0,r.kt)("admonition",{type:"info"},(0,r.kt)("p",{parentName:"admonition"},"For the latest definition of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Pose")," structure, please refer to our\n",(0,r.kt)("a",{parentName:"p",href:"https://github.com/farm-ng/farm-ng-core/blob/main/protos/farm_ng/core/pose.proto"},(0,r.kt)("strong",{parentName:"a"},(0,r.kt)("inlineCode",{parentName:"strong"},"Pose")," protobuf definition")),".")),(0,r.kt)("p",null,"Each pose has an ",(0,r.kt)("inlineCode",{parentName:"p"},"Isometry3F64"),', which is a representation of rigid body transformations in 3D space.\nIn simple terms, it describes how an object moves and rotates in three-dimensional space\nwithout changing its shape.\nThe term "isometry" implies that distances between points remain unchanged during the transformation.'),(0,r.kt)("p",null,"In the context of robotics, ",(0,r.kt)("inlineCode",{parentName:"p"},"Isometry3F64")," is used to describe the movement\nand rotation of a robot in 3D space."),(0,r.kt)("h4",{id:"properties-of-isometry3f64"},"Properties of Isometry3F64"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Translation"),": This represents the linear movement of the robot.\nThis is represented as a 3D vector, where each component (x, y, z) describes movement along that axis."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Rotation"),": This represents the angular movement of the robot.\nThis rotation is represented using ",(0,r.kt)("inlineCode",{parentName:"p"},"Rotation3F64"),", which, in this context, uses the Rz method\nto denote a rotation about the z-axis."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Rz method"),": The Rz method, when applied to Rotation3F64, denotes a rotation about the z-axis.\nIn 3D space, the z-axis typically points upwards, perpendicular to the ground plane\n(assuming the x-y plane represents the ground).\nWhen you rotate an object about the z-axis, it turns around this vertical line,\nmuch like how a spinning top rotates around its central axis."),(0,r.kt)("h3",{id:"resources"},"Resources"),(0,r.kt)("p",null,"The use and multiplication of coordinate frame transforms is a fundamental concept in robotics!\nAs such, there is an abundance of quality, free resources on the topic."),(0,r.kt)("p",null,"For a slightly-less-brief introduction you can refer to ",(0,r.kt)("a",{parentName:"p",href:"https://foxglove.dev/blog/understanding-ros-transforms"},"Understanding ROS Transforms"),"."),(0,r.kt)("p",null,"If you wish to dive deeper on this topic, one option is ",(0,r.kt)("a",{parentName:"p",href:"https://ocw.mit.edu/courses/2-12-introduction-to-robotics-fall-2005/"},"MIT OpenCourseWare - Introduction To Robotics"),"."))}d.isMDXComponent=!0}}]);