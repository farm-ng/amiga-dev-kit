"use strict";(self.webpackChunkamiga_developers_website=self.webpackChunkamiga_developers_website||[]).push([[1477],{4575:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>c,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var i=n(4848),t=n(8453);const r={id:"camera-pointcloud",title:"Camera Pointcloud"},s=void 0,o={id:"examples/camera_pointcloud/camera-pointcloud",title:"Camera Pointcloud",description:"Before diving into this code, here's a quick heads-up on what you'll need to be familiar with:",source:"@site/docs/examples/camera_pointcloud/README.md",sourceDirName:"examples/camera_pointcloud",slug:"/examples/camera_pointcloud/",permalink:"/docs/examples/camera_pointcloud/",draft:!1,unlisted:!1,editUrl:"https://github.com/farm-ng/amiga-dev-kit/tree/main/website/docs/examples/camera_pointcloud/README.md",tags:[],version:"current",frontMatter:{id:"camera-pointcloud",title:"Camera Pointcloud"},sidebar:"examples",previous:{title:"Camera Aruco Detector",permalink:"/docs/examples/camera_aruco_detector/"},next:{title:"Motor State",permalink:"/docs/examples/motor_state/"}},c={},d=[{value:"1. Install the farm-ng Brain ADK package",id:"1-install-the-farm-ng-brain-adk-package",level:3},{value:"2. Setup",id:"2-setup",level:3},{value:"3. Install the example&#39;s dependencies",id:"3-install-the-examples-dependencies",level:3},{value:"4. Execute the Python script",id:"4-execute-the-python-script",level:3},{value:"5. Customize run",id:"5-customize-run",level:3},{value:"6. Code overview",id:"6-code-overview",level:3}];function l(e){const a={a:"a",admonition:"admonition",code:"code",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(a.admonition,{title:"Basic Knowledge Requirements",type:"info",children:[(0,i.jsx)(a.p,{children:"Before diving into this code, here's a quick heads-up on what you'll need to be familiar with:"}),(0,i.jsxs)(a.ol,{children:["\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Python Programming"}),": It's important to have a good grasp of Python, especially with concepts\nlike ",(0,i.jsx)(a.code,{children:"functions"}),", ",(0,i.jsx)(a.code,{children:"loops"}),", and ",(0,i.jsx)(a.code,{children:"classes"}),", since the example utilizes these fundamentals."]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Asynchronous Programming with asyncio"}),": Familiarity with Python's asyncio for writing concurrent\ncode using the ",(0,i.jsx)(a.code,{children:"async/await"})," syntax."]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"3D Point Cloud Data"}),": Understanding the basics of 3D point cloud data.\nYou should be familiar with concepts like depth maps and disparity maps, and how they can be\nconverted into 3D representations of a scene.\nKnowledge of methods such as ",(0,i.jsx)(a.code,{children:"depth_from_disparity"})," and ",(0,i.jsx)(a.code,{children:"depth_to_3d_v2"}),", and data structures\nfor representing 3D data (like tensors), will be especially helpful."]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:"Image Decoding and Tensor Manipulation"}),": Understanding of image data decoding and manipulation,\nparticularly using tensors."]}),"\n",(0,i.jsxs)(a.li,{children:[(0,i.jsx)(a.strong,{children:(0,i.jsx)(a.a,{href:"/docs/concepts/oak_service/",children:"farm-ng Oak Service Overview"})}),":\nThis overview provides a base understanding of the gRPC service the client you create will connect to."]}),"\n"]})]}),"\n",(0,i.jsxs)(a.p,{children:["The requirements to run the\n",(0,i.jsx)(a.a,{href:"https://github.com/farm-ng/farm-ng-amiga/blob/main/py/examples/camera_pointcloud/main.py",children:(0,i.jsx)(a.strong,{children:"Camera Pointcloud"})}),"\nexample are to have a ",(0,i.jsx)(a.a,{href:"/docs/brain/",children:(0,i.jsx)(a.strong,{children:"farm-ng brain"})})," running at least one Oak camera."]}),"\n",(0,i.jsxs)(a.p,{children:["You can either run this example directly on a brain by ",(0,i.jsx)(a.code,{children:"ssh"}),"'ing in,\nor use your local PC.\nIf using your local PC, it should be either connected to the same local network as the brain\nor linked to it through tailscale."]}),"\n",(0,i.jsxs)(a.h3,{id:"1-install-the-farm-ng-brain-adk-package",children:["1. Install the ",(0,i.jsx)(a.a,{href:"/docs/brain/brain-install",children:"farm-ng Brain ADK package"})]}),"\n",(0,i.jsx)(a.h3,{id:"2-setup",children:"2. Setup"}),"\n",(0,i.jsx)(a.admonition,{type:"tip",children:(0,i.jsx)(a.p,{children:"It is recommended to also install these dependencies and run the\nexample in the brain ADK virtual environment."})}),"\n",(0,i.jsx)(a.p,{children:"Create first a virtual environment"}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-bash",children:"python3 -m venv venv\nsource venv/bin/activate\n"})}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-bash",children:"# assuming you're already in the amiga-dev-kit/ directory\ncd farm-ng-amiga/py/examples/pointcloud\n"})}),"\n",(0,i.jsx)(a.h3,{id:"3-install-the-examples-dependencies",children:"3. Install the example's dependencies"}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-bash",children:"pip3 install -r requirements.txt\n"})}),"\n",(0,i.jsx)(a.h3,{id:"4-execute-the-python-script",children:"4. Execute the Python script"}),"\n",(0,i.jsxs)(a.admonition,{type:"info",children:[(0,i.jsxs)(a.p,{children:["To run this script from your PC, you need to update the ",(0,i.jsx)(a.code,{children:"service_config.json"}),"\nby modifying the ",(0,i.jsx)(a.code,{children:"host"})," field with your Amiga brain name."]}),(0,i.jsxs)(a.p,{children:["Please check out ",(0,i.jsx)(a.a,{href:"/docs/concepts/system_overview/#where-to-run-the-examples",children:"Amiga Development 101"}),"\nfor more details."]})]}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-bash",children:"python3 main.py --service-config service_config.json\n"})}),"\n",(0,i.jsx)(a.h3,{id:"5-customize-run",children:"5. Customize run"}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-bash",children:"# usage: amiga-camera-pointcloud [-h] --service-config SERVICE_CONFIG [--save-disparity] [--save-pointcloud]\n#\n# optional arguments:\n#   -h, --help            show this help message and exit\n#   --service-config SERVICE_CONFIG\n#                         The camera config.\n#   --save-disparity      Save the disparity image.\n#   --save-pointcloud     Save the depth image.\n"})}),"\n",(0,i.jsx)(a.h3,{id:"6-code-overview",children:"6. Code overview"}),"\n",(0,i.jsxs)(a.p,{children:["In this example we get the camera calibration from the camera service and use it jointly\nwith the ",(0,i.jsx)(a.code,{children:"disparity"})," image to generate the ",(0,i.jsx)(a.code,{children:"pointcloud"}),"."]}),"\n",(0,i.jsxs)(a.p,{children:["Firstly, we use the ",(0,i.jsx)(a.code,{children:"EventClient"})," to request the camera calibration from the camera service.\nThe camera calibration is an ",(0,i.jsx)(a.code,{children:"oak_pb2.CameraCalibration"})," message that\ncontains the camera intrinsic and extrinsic parameters."]}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-python",children:'# create a client to the camera service\nconfig: EventServiceConfig = proto_from_json_file(args.service_config, EventServiceConfig())\n\ncamera_client = EventClient(config)\n\n# get the calibration message\ncalibration_proto: oak_pb2.OakCalibration =\n                    await camera_client.request_reply("/calibration", Empty(), decode=True)\n\n# NOTE: The OakCalibration message contains the camera calibration data for all the cameras.\n# Since we are interested in the disparity image, we will use the calibration data for the right camera\n# which is the first camera in the list.\ncamera_data: oak_pb2.CameraData = calibration_proto.camera_data[0]\n\n# compute the camera matrix from the calibration data\ncamera_matrix: Tensor = get_camera_matrix(camera_data)\n'})}),"\n",(0,i.jsxs)(a.p,{children:["Below is the code to compute the camera matrix from the calibration data.\nNotice that we cast the ",(0,i.jsx)(a.code,{children:"intrinsic_matrix"})," to a ",(0,i.jsx)(a.code,{children:"Tensor"})," and reshape it to\na 3x3 matrix.\nThis will allow an easy integration with the kornia library."]}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-python",children:'def get_camera_matrix(camera_data: oak_pb2.CameraData) -> Tensor:\n    """Compute the camera matrix from the camera calibration data.\n\n    Args:\n        camera_data (oak_pb2.CameraData): The camera calibration data.\n\n    Returns:\n        Tensor: The camera matrix with shape 3x3.\n    """\n    fx = camera_data.intrinsic_matrix[0]\n    fy = camera_data.intrinsic_matrix[4]\n    cx = camera_data.intrinsic_matrix[2]\n    cy = camera_data.intrinsic_matrix[5]\n\n    return tensor([[fx, 0, cx], [0, fy, cy], [0, 0, 1]])\n'})}),"\n",(0,i.jsxs)(a.p,{children:["Next, we use the ",(0,i.jsx)(a.code,{children:"EventClient"})," to subscribe to the ",(0,i.jsx)(a.code,{children:"disparity"})," path from the camera service.\nThe ",(0,i.jsx)(a.code,{children:"disparity"})," image is an ",(0,i.jsx)(a.code,{children:"oak_pb2.OakImage"})," message that contains the ",(0,i.jsx)(a.code,{children:"disparity"})," image data."]}),"\n",(0,i.jsxs)(a.p,{children:["To compute the ",(0,i.jsx)(a.code,{children:"pointcloud"})," we first need to decode the ",(0,i.jsx)(a.code,{children:"disparity"})," image data to a ",(0,i.jsx)(a.code,{children:"Tensor"}),"\nand then compute the ",(0,i.jsx)(a.code,{children:"pointcloud"})," from the ",(0,i.jsx)(a.code,{children:"disparity"})," image\nusing the kornia method ",(0,i.jsx)(a.code,{children:"depth_from_disparity"})," and ",(0,i.jsx)(a.code,{children:"depth_to_3d_v2"}),"."]}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-python",children:'async for event, message in camera_client.subscribe(\n    SubscribeRequest(uri=uri_pb2.Uri(path="/disparity"), every_n=5), decode=True\n):\n    # cast image data bytes to a tensor and decode\n    disparity_t = decode_disparity(message, image_decoder)  # HxW\n\n    # compute the depth image from the disparity image\n    calibration_baseline: float = 0.075  # m\n    calibration_focal: float = float(camera_matrix[0, 0])\n\n    depth_t = K.geometry.depth.depth_from_disparity(\n        disparity_t, baseline=calibration_baseline, focal=calibration_focal\n    )  # HxW\n\n    # compute the point cloud from the depth image\n    points_xyz = K.geometry.depth.depth_to_3d_v2(depth_t, camera_matrix)  # HxWx3\n\n    # filter out points that are in the range of the camera\n    valid_mask = (points_xyz[..., -1:] >= 0.2) & (points_xyz[..., -1:] <= 7.5)  # HxWx1\n    valid_mask = valid_mask.repeat(1, 1, 3)  # HxWx3\n\n    points_xyz = points_xyz[valid_mask].reshape(-1, 3)  # Nx3\n'})}),"\n",(0,i.jsxs)(a.p,{children:["Below is the code to decode the ",(0,i.jsx)(a.code,{children:"disparity"})," image data to a ",(0,i.jsx)(a.code,{children:"Tensor"}),"."]}),"\n",(0,i.jsx)(a.pre,{children:(0,i.jsx)(a.code,{className:"language-python",children:'def decode_disparity(message: oak_pb2.OakFrame, decoder: ImageDecoder) -> Tensor:\n    """Decode the disparity image from the message.\n\n    Args:\n        message (oak_pb2.OakFrame): The camera frame message.\n        decoder (ImageDecoder): The image decoder.\n\n    Returns:\n        Tensor: The disparity image tensor (HxW).\n    """\n    # decode the disparity image from the message into a dlpack tensor for zero-copy\n    disparity_dl = decoder.decode(message.image_data)\n\n    # cast the dlpack tensor to a torch tensor\n    disparity_t = torch.from_dlpack(disparity_dl)\n\n    return disparity_t[..., 0].float()  # HxW\n'})}),"\n",(0,i.jsxs)(a.p,{children:["Additionally, we can save the ",(0,i.jsx)(a.code,{children:"disparity"})," image and the ",(0,i.jsx)(a.code,{children:"pointcloud"})," to disk by\nusing the ",(0,i.jsx)(a.code,{children:"--save-disparity"})," and ",(0,i.jsx)(a.code,{children:"--save-pointcloud"})," flags respectively."]}),"\n",(0,i.jsx)(a.admonition,{type:"tip",children:(0,i.jsxs)(a.p,{children:["We highly recommend to have some basic knowledge about\n",(0,i.jsx)(a.a,{href:"https://docs.python.org/3/library/asyncio.html",children:(0,i.jsx)(a.strong,{children:(0,i.jsx)(a.code,{children:"asyncio"})})}),"."]})})]})}function h(e={}){const{wrapper:a}={...(0,t.R)(),...e.components};return a?(0,i.jsx)(a,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,a,n)=>{n.d(a,{R:()=>s,x:()=>o});var i=n(6540);const t={},r=i.createContext(t);function s(e){const a=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function o(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(r.Provider,{value:a},e.children)}}}]);